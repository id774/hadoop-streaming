# config/env.conf

# Specify Map Reduce options
TOOLRUNNER_OPTIONS="mapred.reduce.tasks=1"

# Configuration for hadooop root dir
HADOOP_ROOT=/usr/lib/hadoop

# Specify jar of Hadoop Streaming
HADOOP_JAR=$HADOOP_ROOT/contrib/streaming/hadoop-streaming-current.jar

# You should specify to mapper and reducer
MAPPER=mapper.rb
REDUCER=reducer.rb

# Set to hadoop load binary
HADOOP=/usr/bin/hadoop
#HADOOP=$HADOOP_HOME/bin/hadoop

# Specify log file name
JOBLOG=$SCRIPT_HOME/log/job.log

# Specify result file name
RESULTLOG=$SCRIPT_HOME/log/result.log

# Specify runner file
EXEC_RUNNER=$SCRIPT_HOME/script/run

# Specify working hdfs directory name
HDFS_OUT=out
INFILE=s3n://bucket_name/XXX/all_test.txt
#INFILE=s3n://bucket_name/XXX/all.txt
#INFILE=out/part-00000

# Specify tasks before do
$HADOOP dfs -rm -R $HDFS_OUT
$HADOOP fs -expunge

