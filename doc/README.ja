/* README.ja */

名前
 hadoop-streaming-with-ruby - Hadoop によるデータ解析の足がかり

書式
 bin/run

説明
 このソフトウェアは Hadoop を利用してデータの解析をおこなう例である。
 Ruby と Hadoop Streaming を利用する。


[環境設定]

1) 前提条件
ruby, rspec, hadoop のインストールが完了していること。

2) テスト実行
$ cd ~/hadoop-streaming-with-ruby
$ rake spec

Mapper
  単語ごとの長さが返る

Reducer
  単語の平均の長さが返る

Finished in 2.74 seconds
3 examples, 0 failures
のように表示されることを確認する。


[実行方法]

まずは Hadoop を使わずに実行する。

$ script/simple

log/result.log
に平均単語長が出力されているはずなので確認する。

次項のサンプル出力例のようになっていれば OK である。


次に Hadoop Streaming 経由で実行する。

$ bin/run

log/development.log
log/result.log
の内容を確認する。


[出力例]

キーと値は単語の頭文字及び平均の長さとなるはずである。

	NaN
&	3.0422535211267605
'	4.881417537482962
(	5.3380003943995264
-	5.348595008842602
.	5.346032992930087
1	5.304356281602489
2	5.263431542461006
3	5.2399463806970505
4	5.238897396630934
5	5.237849215461155
6	5.236801836266259
7	5.2361828265442725
8	5.2351366851462435
9	5.234518348623853
:	5.2304754630513655
A	4.292707102283558
B	4.590668723146414
C	5.109693155338749
D	5.141757387247279
E	5.226234540037916
F	5.255718017329256
G	5.330306270414366
H	5.24609459407929
I	4.254759829334312
J	4.272484360471939
K	4.284678970809139
L	4.353552029849268
M	4.4474284441645615
N	4.447848756573141
O	4.3762425447316105
P	4.493191699341176
Q	4.500135893883449
R	4.549792020318513
S	4.62705876707892
T	4.57403492744694
U	4.578863420302102
V	4.589133133717958
W	4.599860556506306
X	4.599476618389505
Y	4.583597407446411
Z	4.583636894533027
[	4.639647425621582
]	4.63942758909074
a	4.303291119505056
b	4.329693570622885
c	4.489248842384137
d	4.5438038522076365
e	4.583476574493713
f	4.626020190046831
g	4.650540776867001
h	4.596688738974218
i	4.484832110256991
j	4.48936975268483
k	4.497220450022377
l	4.51879677342996
m	4.477114695760073
n	4.460294716641525
o	4.381135200470083
p	4.448314430996881
q	4.45358887027786
r	4.483932913451053
s	4.5405422408427425
t	4.466253327532082
u	4.469489056846004
v	4.477949797499905
w	4.485099050283539
y	4.4675173989200525
z	4.4675464007150945
|	4.465261127128858


[詳細設定]

 config/env.conf では実行環境に即した様々な設定をおこなうことができる。
これにより実行環境の差異を吸収することができる。

# インストールされた Hadoop のルートディレクトリ
HADOOP_ROOT=/usr/local/hadoop

# Streaming 用の .jar ファイルの場所
HADOOP_JAR=$HADOOP_ROOT/contrib/streaming/hadoop-streaming-0.20.205.0.jar

# Hadoop の実行用バイナリのパス
HADOOP=$HADOOP_HOME/bin/hadoop

# ログの出力先
JOBLOG=$SCRIPT_HOME/log/production.log

このファイルは単にシェルスクリプトとして呼ばれるため、事前処理もそのまま記述できる。
詳細はファイルの内容を参照のこと。


[処理概要]

本ソフトウェアのファイル体系は以下の通りである。

.
|
+- bin
|   |
|   +- run
|        実行ファイル本体
|
+- config
|   |
|   +- env.conf
|        設定ファイル
|
+- db
|   |
|   +- sqlite3.db
|        (RDB を利用する場合) DB の格納先
|
+- doc
|   |
|   +- README.ja
|        本ドキュメント
|
+- lib 処理に必要な主要なファイルが格納される
|   |
|   +- filter.rb
|   |    集計用フィルタ
|   +- hive.rb
|   |    Hive 用 Strorage クラス
|   +- mapper.rb
|   |    Mapper
|   +- reducer.rb
|   |    Reducer
|   +- resolver.rb
|   |    名前解決をおこなう
|   +- sqlite.rb
|        SQLite 用 Strorage クラス
|
+- data
|   |
|   +- shakespeare
|        サンプルの入力データ例となるシェークスピアの作品集データ
|
+- log ログファイルが格納される
|   |
|   +- production.log
|   |    処理経過が出力されるログファイル
|   +- result.log
|        集計結果が格納されるログファイル
|
+- script シェルスクリプトが格納される
|   |
|   +- migrate
|   |    HiveQL のマイグレーション用スクリプト
|   +- run
|   |    Hadoop Streaming に処理を受け渡すスクリプト本体
|   +- simple
|        Hadoop を経由せず UNIX パイプを利用する場合のスクリプト
|
+- spec RSpec によるテストコードが格納される
|
+- vendor 外部ライブラリ


[RDB の利用]

他の KVS, RDB 等を利用したい場合は Storage クラスを実装し
.get .put メソッドで入出力できるようラップする。


[MapReduce]

Mapper と Reducer は標準入出力を扱うためホワイトボックステストが困難である。
そのためできるだけ処理を外部クラスに切り出し軽くする必要がある。

Mapper の引数

集計条件を指定する。
test の場合、テストを実施する。

Reducer の引数

DB をラップするクラスファイルを指定する。
Storage クラスを require するファイルを指定する。



